library(neuralnet)
library(readr)
library(mice)
library(VIM)
kepler <- read_csv("~/Documents/GitHub/ist687-group-kss/cumulative.csv") # get data
# clean data
kepler <- kepler[, -c(4,31, 32)]
View(kepler)
md.pattern(kepler)
aggr_plot <- aggr(kepler, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
library(sqldf)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration, koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
View(clean)
clean <- clean[, -c(2)]
neuralnet(koi_disposition~., data = clean, hidden = c(100, 50, 20, 10, 3, 1))
nnet_kepler <- neuralnet(koi_disposition~., data = clean, hidden = c(100, 50, 20, 10, 3, 1), threshold=0.01,
algorithm = "rprop+")
View(clean)
names(clean)
nnet_kepler <- neuralnet(koi_disposition~koi_period+koi_duration+koi_depth+koi_prad+koi_model_snr+
koi_steff+koi_srad, data = clean, hidden = c(100, 50, 20, 10, 3, 1), threshold=0.01,
algorithm = "rprop+")
scale(clean[, -c(1)])
clean[, -c(1)] <- scale(clean[, -c(1)])
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
library(caret)
install.packages("caret")
library(caret)
preProcess(clean, method = c("center", "scale"))
clean_scaled <- preProcess(clean, method = c("center", "scale"))
View(clean_scaled)
preProcess(clean, method = c("center", "scale"))
predict(preProcess(clean, method = c("center", "scale")), clean)
View(clean)
clean <- predict(preProcess(clean, method = c("center", "scale"))
clean <- predict(preProcess(clean, method = c("center", "scale")))
clean <- predict(preProcess(clean, method = c("center", "scale")), clean)
View(clean)
nnet_kepler <- neuralnet(koi_disposition~koi_period+koi_duration+koi_depth+koi_prad+koi_model_snr+
koi_steff+koi_srad, data = clean, hidden = c(100, 50, 20, 10, 3, 1), threshold=0.01,
algorithm="rprop+")
library(neuralnet)
library(neuralnet)
nnet_kepler <- neuralnet(koi_disposition~koi_period+koi_duration+koi_depth+koi_prad+koi_model_snr+
koi_steff+koi_srad, data = clean, hidden = c(20, 10, 3, 1), threshold=0.01,
algorithm="rprop+")
library(nnet)
nnet_kepler <- nnet(koi_disposition~., data = kepler)
nnet_kepler <- nnet(koi_disposition~., data = clean)
mosaic::tally(clean$koi_disposition)
nnet_kepler <- nnet(koi_disposition~., data = clean, size = 10)
nnet_kepler <- nnet(koi_disposition~., data = clean, size = 10)
library(neuralnet)
terms_list <- names(clean)
terms_list[2:]
terms_list[2:8]
rest_terms <- paste(terms_list[2:length(terms_list)], sep = "~")
rest_terms <- paste(terms_list[2:length(terms_list)], sep = "+")
f <- as.formula(paste("koi_disposition~", rest_terms))
length(terms_list)
paste(terms_list[2:length(terms_list)], sep = "+")
paste(c(terms_list[2:length(terms_list)]), sep = "+")
c(terms_list[2:length(terms_list)])
terms_list <- names(clean)
terms_list <- list(names(clean))
terms_list[2:length(terms_list)]
rest_terms <- paste(c(terms_list[2:length(terms_list)]), sep = "+")
terms_list <- list(names(clean))[2:8]
terms_list <- names(clean)[2:8]
rest_terms <- paste(terms_list, sep = "+")
paste(terms_list)
paste0(terms_list)
paste(terms_list, collapse = "+")
terms_list <- names(clean)[2:8]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("koi_disposition~", rest_terms))
f
neuralnet(f, data = clean)
View(clean)
neuralnet(f, data = clean, linear.output = FALSE)
class.ind(as.factor(clean$koi_disposition)))
class.ind(as.factor(clean$koi_disposition))
one_hot <- class.ind(as.factor(clean$koi_disposition))
clean[, -c(1)]
clean <- base::cbind(one_hot, clean[, -c(1)])
View(clean)
terms_list <- names(clean)[3:9]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("koi_disposition~", rest_terms))
library(nnet)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(preProcess(clean, method = c("center", "scale")), clean)
library(caret)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
library(nnet)
library(readr)
library(mice)
library(VIM)
library(sqldf)
library(caret)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(preProcess(clean, method = c("center", "scale")), clean)
View(clean)
terms_list <- names(clean)[2:9]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("koi_disposition", rest_terms))
f <- as.formula(paste("koi_disposition~", rest_terms))
nnet(f, data = clean, size = 20)
nnet(f, data = clean, size = 20, softmax = TRUE)
f
View(clean)
terms_list <- names(clean)[2:8]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("koi_disposition~", rest_terms))
nnet(f, data = clean, size = 20, softmax = TRUE)
nnet(f, data = clean, size = 20, softmax = TRUE)
nnet(f, data = clean, size = 20, softmax = TRUE)
clean[,-1]
f <- as.formula(paste("CONFIRMED+FALSE~", rest_terms))
nnet(f, data = clean[,-1], size = 20, softmax = TRUE)
library(mltools)
install.packages("mltools")
one_hot(clean)
library(mltools)
one_hot(clean)
one_hot(clean, cols = c(1))
one_hot(clean, cols = c(1), dropCols = TRUE)
one_hot(dt = clean, cols = c(1), dropCols = TRUE)
install.packages("onehot")
library(onehot)
onehot(clean)
onehot(data = clean)
library(caret)
tmp <- dummyVars(koi_disposition~., data = clean)
View(tmp)
predict(tmp)
predict(tmp, newdata = tmp)
tmp_2 <- predict(tmp, newdata = tmp_2)
tmp <- predict(tmp, newdata = tmp)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(preProcess(clean, method = c("center", "scale")), clean)
View(clean)
clean <- as.data.frame(clean)
tmp <- dummyVars(koi_disposition~., data = clean)
tmp <- predict(tmp, newdata = tmp)
tmp <- data.frame(dummyVars(koi_disposition~., data = clean))
source('~/Documents/GitHub/ist687-group-kss/tf_neuralnet.R')
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(preProcess(clean, method = c("center", "scale")), clean)
str(clean)
library(mltools)
library(mltools)
library(onehot)
onehot(clean)
clean <- as.data.frame(clean)
onehot(clean)
typeof(clean)
unlist(clean)
as.data.frame(unlist(clean))
typeof(clean)
clean <- data.frame(matrix(unlist(clean), nrow=7016, byrow=T),stringsAsFactors=FALSE)
View(clean)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(preProcess(clean, method = c("center", "scale")), clean)
str(clean)
typeof(clean)
matrix(clean)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean_scaled$data
View(clean_scaled)
View(clean_scaled)
new_df <- NULL
clean <- predict(clean_scaled, new_df)
clean <- predict(clean_scaled, clean)
View(clean)
clean[, -1]
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean[,-1] <- scale(clean[, -1])
# check that we get mean of 0 and sd of 1
colMeans(clean)  # faster version of apply(scaled.dat, 2, mean)
# check that we get mean of 0 and sd of 1
colMeans(clean[,-1])  # faster version of apply(scaled.dat, 2, mean)
apply(clean[,-1], 2, sd)
typeof(clean)
as.matrix(clean)
clean <- as.data.frame(as.matrix(clean))
typeof(clean)
View(clean)
clean <- predict(clean_scaled, clean)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(clean_scaled, clean)
View(clean)
terms_list <- names(clean)[2:8]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("koi_disposition~", rest_terms))
nnet(f, data = clean[,-1], size = 20, softmax = TRUE)
nnet(f, data = clean, size = 20, softmax = TRUE)
clean <- as.data.table(clean)
library(mltools)
mltools::one_hot(clean)
tmp <- mltools::one_hot(clean)
View(tmp)
str(clean)
clean$koi_disposition <- as.factor(clean$koi_disposition)
tmp <- mltools::one_hot(clean)
View(tmp)
clean <- mltools::one_hot(clean)
names(clean)
names(clean)[1:2]
names(clean)[1:2] <- c("conf", "falsep")
terms_list <- names(clean)[3:8]
rest_terms <- paste(terms_list, collapse = "+")
terms_list <- names(clean)[3:9]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("conf+falsep~", rest_terms))
nnet(f, data = clean, size = 20, softmax = TRUE)
nnet(f, data = clean, size = 20)
my_model <- nnet(f, data = clean, size = 20)
View(my_model)
my_model$
sample(length(clean))
length(clean)
my_model$
sample(nrow(clean))
smp_size <- floor(0.75 * nrow(clean))
train_ind <- sample(seq_len(nrow(clean)), size = smp_size)
train <- clean[train_ind, ]
test <- clean[-train_ind, ]
terms_list <- names(clean)[3:9]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("conf+falsep~", rest_terms))
my_model <- nnet(f, data = test, size = 20)
my_other_model <- neuralnet(f, data = train)
my_model <- nnet(f, data = test, size = 50)
my_model <- nnet(f, data = test, size = 50)
predict(my_model, test)
test$predicted <- predict(my_model, test)
View(test)
library(neuralnet)
library(readr)
library(mice)
library(VIM)
library(sqldf)
library(caret)
library(mltools)
kepler <- read_csv("~/Documents/GitHub/ist687-group-kss/cumulative.csv") # get data
# clean data
kepler <- kepler[, -c(4,31, 32)]
md.pattern(kepler)
aggr_plot <- aggr(kepler, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
tempData <- mice(kepler,m=5,maxit=2,meth='cart',seed=500)
summary(tempData)
tmp <- tempData$data
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
typeof(clean)
typeof(as.data.frame(clean))
typeof(kepler)
#
# tempData <- mice(kepler,m=5,maxit=2,meth='cart',seed=500)
# summary(tempData)
#
# tmp <- tempData$data
airquality
#
# tempData <- mice(kepler,m=5,maxit=2,meth='cart',seed=500)
# summary(tempData)
#
# tmp <- tempData$data
airquality <- airquality
View(aggr_plot)
View(airquality)
typeof(airquality)
remove(airquality)
clean <- sqldf("SELECT koi_disposition, koi_pdisposition, koi_period, koi_duration,
koi_depth, koi_prad, koi_model_snr, koi_steff, koi_srad
FROM kepler WHERE koi_disposition!='CANDIDATE' AND koi_depth IS NOT NULL")
clean <- clean[, -c(2)]
clean_scaled <- preProcess(clean, method = c("center", "scale"))
clean <- predict(clean_scaled, clean)
clean$koi_disposition <- as.factor(clean$koi_disposition)
View(clean)
class.ind(clean$koi_disposition)
cbind(clean[, 2:9], class.ind(clean$koi_disposition))
clean[, 2:9]
clean[2:9]
clean[, c(2:9)]
clean[, 2:8]
cbind(clean[, 2:8], class.ind(clean$koi_disposition))
clean <- cbind(clean[, 2:8], class.ind(clean$koi_disposition))
View(clean)
names(clean)[8:9] <- c("conf", "falsep")
View(clean)
set.seed(123)
smp_size <- floor(0.75 * nrow(clean))
train_ind <- sample(seq_len(nrow(clean)), size = smp_size)
train <- clean[train_ind, ]
train <- clean[train_ind, ]
test_x <- clean[-train_ind, ]
View(train)
terms_list <- names(clean)[1:7]
rest_terms <- paste(terms_list, collapse = "+")
f <- as.formula(paste("conf+falsep~", rest_terms))
f
my_model <- neuralnet(f,
data = test,
hidden = c(7,5,3),
linear.output = FALSE,
lifesign = "full")
my_model <- neuralnet(f,
data = train,
hidden = c(7,5,3),
linear.output = FALSE,
lifesign = "full")
summary(my_model)
library(tensorflow)
my_model <- neuralnet(f,
data = train,
hidden = c(7,5,3),
linear.output = FALSE,
lifesign = "full",
threshold = 1.0)
View(my_model)
summary(my_model)
predict(my_model, test)
predict(my_model, test_x)
predicted <- predict(my_model, test_x)
test_x <- cbind(test_x, predicted)
View(test_x)
test_x$1
names(test_x)[10:11] <- c("conf_p", "falsep_p")
round(test_x$conf_p)
test_x$conf_p <- round(test_x$conf_p)
test_x$falsep_p <- round(test_x$falsep_p)
which(sum(test_x$conf_p, test_x$falsep_p) == 0)
which(sum(test_x$conf_p, test_x$falsep_p) == 1)
sum(test_x$conf_p, test_x$falsep_p) == 1
sum(test_x$conf_p, test_x$falsep_p)
test_x$conf_p + test_x$falsep_p
which(test_x$conf_p + test_x$falsep_p == 1)
which(test_x$conf_p + test_x$falsep_p == 0)
which(test_x$conf_p + test_x$falsep_p == 2)
test_x$conf == test_x$conf_p
nrow(test_x$conf == test_x$conf_p)
which(test_x$conf == test_x$conf_p)
length(which(test_x$conf == test_x$conf_p))
(length(which(test_x$conf == test_x$conf_p))/length(test_x))*100
length(test_x)
(length(which(test_x$conf == test_x$conf_p))/nrow(test_x))*100
accuracy <- (length(which(test_x$conf == test_x$conf_p))/nrow(test_x))*100
my_model$result.matrix
plot(my_model)
my_model <- neuralnet(f,
data = train,
hidden = c(7,5,3),
linear.output = FALSE,
lifesign = "full",
threshold = 0.05)
my_model <- neuralnet(f,
data = train,
hidden = c(7,5,3),
linear.output = TRUE,
lifesign = "full",
threshold = 0.05)
predicted <- predict(my_model, test_x)
summary(my_model)
predict(my_model, test_x)
my_model <- neuralnet(f,
data = train,
hidden = c(7,5,2),
linear.output = TRUE,
lifesign = "full",
threshold = 0.05,
rep = 10)
my_model <- neuralnet(f,
data = train,
hidden = c(7,5,2),
linear.output = TRUE,
lifesign = "full",
threshold = 0.6,
rep = 1)
View(train)
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(1, 7)) %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 25, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 5, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(2, activation = "softmax")
library(dplyr)
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(1, 7)) %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 25, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 5, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(2, activation = "softmax")
library(tensorflow)
library(keras)
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(1, 7)) %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 25, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 5, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(2, activation = "softmax")
n
install_tensorflow()
